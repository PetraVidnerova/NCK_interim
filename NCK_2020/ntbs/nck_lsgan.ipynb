{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSGAN\n",
    "\n",
    "Least Squares Generative Adversial Network pro generování obrázků disků.\n",
    "\n",
    "<img src=\"lsgan_paper.jpg\" alt=\"lsgan example\" style=\"width: 700px;\"/>\n",
    "\n",
    "References:\n",
    "- [Least Squares Generative Adversarial Networks](https://arxiv.org/pdf/1611.04076.pdf). X. Mao et al., 20156."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reálné obrázky\n",
    "\n",
    "Reálné obrázky disků jsou uloženy v .tfrecords databázi vytvořené pomocí tfrec2gan skriptu.\n",
    "Pro názornost uvadíme příklad uložených fotografií:\n",
    "<table><tr>\n",
    "    <td><img src=\"ExtractedImages\\img_3.jpg\" alt=\"img_3\" style=\"width: 64px;\"/></td>\n",
    "    <td><img src=\"ExtractedImages\\img_4.jpg\" alt=\"img_4\" style=\"width: 64px;\"/></td>\n",
    "    <td><img src=\"ExtractedImages\\img_5.jpg\" alt=\"img_5\" style=\"width: 64px;\"/></td>\n",
    "    <td><img src=\"ExtractedImages\\img_6.jpg\" alt=\"img_6\" style=\"width: 64px;\"/></td>\n",
    "    <td><img src=\"ExtractedImages\\img_7.jpg\" alt=\"img_7\" style=\"width: 64px;\"/></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from skimage.transform import resize\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIDmodel = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "FID_BATCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0).astype('float16')\n",
    "        # store        \n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)\n",
    "\n",
    "def calculate_fid(model, act1, images2):\n",
    "    # calculate activations\n",
    "    #act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_fn(tfrecord):\n",
    "  ximg = 64\n",
    "  yimg = 48\n",
    "  # Extract features\n",
    "  features = {\n",
    "    'fpath': tf.io.FixedLenFeature([1], tf.string),\n",
    "    'image': tf.io.FixedLenFeature([ximg * yimg], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([6], tf.float32)\n",
    "  }\n",
    "\n",
    "  # Extract the data record\n",
    "  sample = tf.io.parse_single_example(tfrecord, features)\n",
    "  fpath = sample['fpath']\n",
    "  image = sample['image']\n",
    "  label = sample['label']\n",
    "\n",
    "  fpath = tf.cast(fpath, tf.string)\n",
    "\n",
    "  image = tf.reshape(image, [yimg, ximg, 1])  \n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1  \n",
    "\n",
    "  coords = tf.cast(label, 'float32')\n",
    "  attrs = coords\n",
    "\n",
    "  return image, attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reals.\n"
     ]
    }
   ],
   "source": [
    "xres = 64; yres=48; dstype = 'train'\n",
    "tfrecord_file = f\"E:\\\\NCK\\\\gan_{xres}{yres}{dstype}.tfrecord\"\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "dataset = dataset.map(_extract_fn)\n",
    "dataset = dataset.repeat()\n",
    "#dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(4)\n",
    "train_dataset = dataset\n",
    "\n",
    "fiddataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "fiddataset = fiddataset.map(_extract_fn)\n",
    "fiddataset = fiddataset.repeat()\n",
    "fiddataset = fiddataset.batch(FID_BATCH)\n",
    "\n",
    "for item in fiddataset.take(1):\n",
    "  images_real, _ = item\n",
    "images_real = (images_real + 1.) * 127.5\n",
    "images_real = tf.concat((images_real,)*3, axis=3)\n",
    "images_real = scale_images(images_real.numpy(), (299,299,3))\n",
    "#images_real = preprocess_input(images_real).astype('float16')\n",
    "images_real = preprocess_input(images_real)\n",
    "act_real = FIDmodel.predict(images_real)\n",
    "del images_real\n",
    "print(\"Done reals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 64x48 Generator\n",
    "def make_generator_model48():\n",
    "  gf_dim = 64\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Dense(gf_dim * 8 * 3 * 4, input_shape=(100,)))\n",
    "  model.add(layers.Reshape((3, 4, gf_dim * 8)))  # (4, 3, 512)\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Reshape((3, 4, gf_dim * 8)))  # (4, 4, 512)\n",
    "  assert model.output_shape == (None, 3, 4, 512)  # Note: None is the batch size\n",
    "  \n",
    "  model.add(layers.Conv2DTranspose(gf_dim * 4, (5, 5), strides=(2, 2), padding='SAME'))\n",
    "  assert model.output_shape == (None, 6, 8, 256)\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(gf_dim * 2, (5, 5), strides=(2, 2), padding='SAME'))\n",
    "  assert model.output_shape == (None, 12, 16, 128)\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(gf_dim * 1, (5, 5), strides=(2, 2), padding='SAME'))\n",
    "  assert model.output_shape == (None, 24, 32, 64)\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='SAME', activation='tanh'))\n",
    "  assert model.output_shape == (None, 48, 64, 1)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6144)              620544    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 3, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 3, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 3, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 3, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 8, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 6, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 6, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 12, 16, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 12, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 12, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 24, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 24, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 24, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 48, 64, 1)         1601      \n",
      "=================================================================\n",
      "Total params: 4,927,233\n",
      "Trainable params: 4,925,313\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model48()\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "#plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "print(generator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 64x48 Discriminator\n",
    "def make_discriminator_model48():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.InputLayer(input_shape=(48, 64, 1)))\n",
    "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='SAME'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='SAME'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='SAME'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='SAME'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00029361]], shape=(1, 1), dtype=float32)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_94 (Conv2D)           (None, 24, 32, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 24, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 12, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 12, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 6, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 6, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 6, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 3, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 3, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 3, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6145      \n",
      "=================================================================\n",
      "Total params: 4,313,089\n",
      "Trainable params: 4,311,297\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model48()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss - see train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = np.random.normal(size=[num_examples_to_generate, noise_dim]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss computed directly in train_step\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    #noise = np.random.uniform(-1, 1, size=[BATCH_SIZE, noise_dim]).astype(np.float32)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      d_real_logits = discriminator(images, training=True)\n",
    "      d_fake_logits = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = tf.reduce_mean(tf.nn.l2_loss(d_fake_logits - tf.ones_like(d_fake_logits)))\n",
    "      d_loss_real = tf.reduce_mean(tf.nn.l2_loss(d_real_logits - tf.ones_like(d_real_logits)))\n",
    "      d_loss_fake = tf.reduce_mean(tf.nn.l2_loss(d_fake_logits - tf.zeros_like(d_real_logits)))\n",
    "      disc_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):  \n",
    "  epoch = 0\n",
    "  while epoch < EPOCHS:\n",
    "    epoch += 1\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    for image_batch in dataset.take(1000):\n",
    "      g_loss, d_loss = train_step(image_batch[0])\n",
    "\n",
    "    print(g_loss.numpy(), d_loss.numpy())\n",
    "\n",
    "    generate_and_save_images(generator, epoch, seed)\n",
    "\n",
    "    # Compute FID for 10000 example\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "    #if False:\n",
    "      print(\"Calculating FID ... \", end=\"\", flush=True)\n",
    "      fid_noise = np.random.normal(size=[FID_BATCH, noise_dim]).astype(np.float32)\n",
    "      fid_fake=np.empty([FID_BATCH, 48, 64, 1])\n",
    "      dn = 100\n",
    "      for i in range(FID_BATCH//dn):\n",
    "        fid_batch = fid_noise[i*dn:(i+1)*dn]\n",
    "        #print(i, fid_batch.shape)\n",
    "        g = generator(fid_batch, training=False)\n",
    "        g = (g + 1.) * 127.5\n",
    "        fid_fake[i*dn:(i+1)*dn] = g.numpy()\n",
    "      fid_fake = np.concatenate((fid_fake,)*3, axis=3)\n",
    "      fid_fake = np.rint(fid_fake).clip(0, 255).astype(np.uint8)\n",
    "      fid_fake = fid_fake.astype('float32')\n",
    "      fid_fake = scale_images(fid_fake, (299, 299, 3))\n",
    "      images_fake = preprocess_input(fid_fake)\n",
    "\n",
    "      fid_start = time.time()\n",
    "      fid = calculate_fid(FIDmodel, act_real, images_fake)\n",
    "      fid_end = time.time()\n",
    "      msg = f\"{fid:6.2f}, time {fid_end - fid_start:.2f} sec\"\n",
    "      print(msg)\n",
    "      with open(\"lsgan_images/fid.txt\", \"a+\") as fidfile:\n",
    "        fidfile.writelines([f\"{epoch:03}_FID {msg}\\n\"])\n",
    "\n",
    "\n",
    "    print (f\"Time for epoch {epoch} is {time.time()-epoch_start:.2f} sec\")\n",
    "\n",
    "  generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  ximg = 64\n",
    "  yimg = 48\n",
    "  \n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  g = predictions\n",
    "  g = (g + 1.) * 127.5\n",
    "  canvas = np.empty((yimg * 4, ximg * 4, 1))\n",
    "  c = 0\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      c = c + 1\n",
    "      canvas[j * yimg:(j + 1) * yimg, i * ximg:(i + 1) * ximg] = g[c-1]\n",
    "\n",
    "  image = np.rint(canvas).clip(0, 255).astype(np.uint8)\n",
    "  image = np.squeeze(image)\n",
    "  image = Image.fromarray(image)\n",
    "  image.save(f\"lsgan_images/fake_{epoch*1000}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_real_images(dataset):\n",
    "  ximg = 64\n",
    "  yimg = 48\n",
    "\n",
    "  for images in dataset.take(1):\n",
    "    g = (images[0][:16] + 1.) * 127.5\n",
    "\n",
    "  canvas = np.empty((yimg * 4, ximg * 4, 1))\n",
    "  c = 0\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      c = c + 1\n",
    "      canvas[j * yimg:(j + 1) * yimg, i * ximg:(i + 1) * ximg] = g[c-1]\n",
    "\n",
    "  image = np.rint(canvas).clip(0, 255).astype(np.uint8)\n",
    "  image = np.squeeze(image)\n",
    "  image = Image.fromarray(image)\n",
    "  image.save(\"lsgan_images/reals.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ... \n",
      "11.802664 1.9922061\n",
      "Calculating FID ... 388.52, time 10.05 sec\n",
      "Time for epoch 1 is 39.19 sec\n",
      "17.617922 1.7316492\n",
      "Time for epoch 2 is 20.02 sec\n",
      "13.723892 1.9549859\n",
      "Time for epoch 3 is 20.18 sec\n",
      "15.106436 0.734089\n",
      "Time for epoch 4 is 20.25 sec\n",
      "16.643465 1.3533058\n",
      "Calculating FID ... 415.71, time 7.26 sec\n",
      "Time for epoch 5 is 35.43 sec\n",
      "9.169331 1.8442205\n",
      "Time for epoch 6 is 20.14 sec\n",
      "9.457615 1.4756974\n",
      "Time for epoch 7 is 20.26 sec\n",
      "19.395771 1.7670639\n",
      "Time for epoch 8 is 20.22 sec\n",
      "13.306315 0.8929231\n",
      "Time for epoch 9 is 20.29 sec\n",
      "14.108548 1.9773176\n",
      "Calculating FID ... 409.71, time 8.24 sec\n",
      "Time for epoch 10 is 36.40 sec\n",
      "19.172937 0.81413305\n",
      "Time for epoch 11 is 20.08 sec\n",
      "7.90804 2.7169616\n",
      "Time for epoch 12 is 20.23 sec\n",
      "13.389352 2.1111858\n",
      "Time for epoch 13 is 20.22 sec\n",
      "9.584326 2.4783592\n",
      "Time for epoch 14 is 20.21 sec\n",
      "12.175301 0.5488465\n",
      "Calculating FID ... 414.05, time 8.04 sec\n",
      "Time for epoch 15 is 35.79 sec\n",
      "15.426506 0.3543371\n",
      "Time for epoch 16 is 20.03 sec\n",
      "18.241991 1.4266056\n",
      "Time for epoch 17 is 20.24 sec\n",
      "13.377481 0.503453\n",
      "Time for epoch 18 is 20.23 sec\n",
      "19.800076 1.2092013\n",
      "Time for epoch 19 is 20.21 sec\n",
      "17.289923 0.4543482\n",
      "Calculating FID ... 397.31, time 8.19 sec\n",
      "Time for epoch 20 is 35.98 sec\n",
      "17.965109 0.6884676\n",
      "Time for epoch 21 is 20.04 sec\n",
      "24.258581 1.2718132\n",
      "Time for epoch 22 is 20.27 sec\n",
      "16.073345 0.5570767\n",
      "Time for epoch 23 is 20.27 sec\n",
      "14.805981 0.41825336\n",
      "Time for epoch 24 is 20.25 sec\n",
      "17.11506 0.08635311\n",
      "Calculating FID ... 376.42, time 9.31 sec\n",
      "Time for epoch 25 is 37.61 sec\n",
      "15.233372 0.3392551\n",
      "Time for epoch 26 is 20.06 sec\n",
      "11.656227 1.0761943\n",
      "Time for epoch 27 is 20.24 sec\n",
      "18.756744 0.5186203\n",
      "Time for epoch 28 is 20.22 sec\n",
      "22.082264 1.287835\n",
      "Time for epoch 29 is 20.21 sec\n",
      "18.921421 0.36737692\n",
      "Calculating FID ... 368.67, time 8.50 sec\n",
      "Time for epoch 30 is 36.21 sec\n",
      "14.857984 0.15841615\n",
      "Time for epoch 31 is 20.02 sec\n",
      "12.9382715 0.5448414\n",
      "Time for epoch 32 is 20.23 sec\n",
      "22.534327 0.7780046\n",
      "Time for epoch 33 is 20.20 sec\n",
      "15.598942 0.85781837\n",
      "Time for epoch 34 is 20.22 sec\n",
      "10.455942 1.7211113\n",
      "Calculating FID ... 381.92, time 8.33 sec\n",
      "Time for epoch 35 is 36.11 sec\n",
      "13.305776 0.44350654\n",
      "Time for epoch 36 is 20.00 sec\n",
      "17.987938 0.49456874\n",
      "Time for epoch 37 is 20.20 sec\n",
      "12.538021 0.5817249\n",
      "Time for epoch 38 is 20.20 sec\n",
      "14.667925 0.46085572\n",
      "Time for epoch 39 is 20.18 sec\n",
      "19.169376 0.26138255\n",
      "Calculating FID ... 354.49, time 7.92 sec\n",
      "Time for epoch 40 is 35.69 sec\n",
      "14.612358 0.34669942\n",
      "Time for epoch 41 is 20.05 sec\n",
      "17.696882 0.4613448\n",
      "Time for epoch 42 is 20.22 sec\n",
      "14.549 0.40197992\n",
      "Time for epoch 43 is 20.21 sec\n",
      "15.263964 0.12976603\n",
      "Time for epoch 44 is 20.19 sec\n",
      "13.954147 0.38096827\n",
      "Calculating FID ... 411.77, time 7.92 sec\n",
      "Time for epoch 45 is 35.67 sec\n",
      "16.161983 0.26000527\n",
      "Time for epoch 46 is 20.04 sec\n",
      "21.783295 0.6263593\n",
      "Time for epoch 47 is 20.21 sec\n",
      "8.55047 1.4762479\n",
      "Time for epoch 48 is 20.20 sec\n",
      "18.800465 0.5867368\n",
      "Time for epoch 49 is 20.17 sec\n",
      "15.107985 0.1038169\n",
      "Calculating FID ... 389.81, time 8.16 sec\n",
      "Time for epoch 50 is 35.89 sec\n"
     ]
    }
   ],
   "source": [
    "#===\n",
    "print(\"Start training ... \")\n",
    "f = open(\"lsgan_images/fid.txt\", \"w\"); f.close()\n",
    "save_real_images(train_dataset)\n",
    "train(train_dataset, EPOCHS)\n",
    "#==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td><img src=\"lsgan_images\\fake_1000.jpg\"  alt=\"fake_1000\"  style=\"width: 256px;\"/></td>\n",
    "    <td><img src=\"lsgan_images\\fake_5000.jpg\"  alt=\"fake_5000\"  style=\"width: 256px;\"/></td>\n",
    "    <td><img src=\"lsgan_images\\fake_10000.jpg\" alt=\"fake_10000\" style=\"width: 256px;\"/></td>\n",
    "    <td><img src=\"lsgan_images\\fake_15000.jpg\" alt=\"fake_15000\" style=\"width: 256px;\"/></td>    \n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td><img src=\"lsgan_images\\fake_20000.jpg\" alt=\"fake_20000\" style=\"width: 256px;\"/></td>\n",
    "    <td><img src=\"lsgan_images\\fake_30000.jpg\" alt=\"fake_30000\" style=\"width: 256px;\"/></td>\n",
    "    <td><img src=\"lsgan_images\\fake_40000.jpg\" alt=\"fake_40000\" style=\"width: 256px;\"/></td>\n",
    "    <td><img src=\"lsgan_images\\fake_50000.jpg\" alt=\"fake_50000\" style=\"width: 256px;\"/></td>\n",
    "</tr></table>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nck_net\n",
    "\n",
    "Konvuluční síť pro učení optimální pozice robota pro provedení úchopu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 64\n",
    "ximg = 64\n",
    "yimg = 48\n",
    "\n",
    "GLOBAL_BATCH_SIZE = 64\n",
    "TEST_DATABASE_LENGTH = 988\n",
    "DEPTH = 8\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(res, ximg, yimg):\n",
    "\n",
    "  def _extract_fn(tfrecord):\n",
    "    # Extract features\n",
    "    features = {\n",
    "      'fpath': tf.io.FixedLenFeature([1], tf.string),\n",
    "      'image': tf.io.FixedLenFeature([ximg * yimg], tf.int64),\n",
    "      'label': tf.io.FixedLenFeature([6], tf.float32)\n",
    "    }\n",
    "\n",
    "    # Extract the data record\n",
    "    sample = tf.io.parse_single_example(tfrecord, features)\n",
    "    fpath = sample['fpath']\n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "\n",
    "    fpath = tf.cast(fpath, tf.string)\n",
    "\n",
    "    image = tf.reshape(image, [ximg, yimg, 1])\n",
    "    image = tf.cast(image, 'float32')\n",
    "\n",
    "    coords = tf.cast(label, 'float32')\n",
    "\n",
    "    return fpath, image, coords\n",
    "\n",
    "  dstype = 'train'\n",
    "  tfrecord_file = f\"../gan_6448train.tfrecord\"\n",
    "  dataset = tf.data.TFRecordDataset([tfrecord_file])\n",
    "  dataset = dataset.map(_extract_fn)\n",
    "  train_dataset = dataset.shuffle(buffer_size=3000, reshuffle_each_iteration=False)\n",
    "\n",
    "  dstype = 'faketrain'\n",
    "  tfrecord_file = f\"../ganfake_644834.tfrecord\"\n",
    "  dataset = tf.data.TFRecordDataset([tfrecord_file])\n",
    "  dataset = dataset.map(_extract_fn)\n",
    "  faketrain_dataset = dataset.shuffle(buffer_size=3000, reshuffle_each_iteration=False)\n",
    "\n",
    "  dstype = 'test'\n",
    "  tfrecord_file = f\"../gan_6448test.tfrecord\"\n",
    "  dataset = tf.data.TFRecordDataset([tfrecord_file])\n",
    "  test_dataset = dataset.map(_extract_fn)\n",
    "  #test_dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "  return train_dataset, test_dataset, faketrain_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(depth=1):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.InputLayer(input_shape=(64, 48, 1)))\n",
    "  for i in range(depth):\n",
    "    model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(128, activation='relu'))\n",
    "  model.add(layers.Dense(6))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y,yhat):\n",
    "  x = y-yhat\n",
    "  #norms = tf.norm(x, axis=1, ord=1)\n",
    "  norms = tf.norm(x, axis=1, ord=2)\n",
    "  #norms = tf.norm(x, axis=1, ord=np.inf)\n",
    "  loss = tf.math.reduce_mean(norms)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validity_tf(err):\n",
    "  err_rx, err_ry, err_rz, err_x, err_y, err_z = tf.unstack(err, axis=1)\n",
    "  cond1 = abs(err_rx) + abs(err_ry) < 0.052\n",
    "  cond2 = abs(err_x) + abs(err_y) < 0.007\n",
    "  cond3_ur = abs(err_z) < 0.04\n",
    "  cond3_ku = abs(err_z) + 0.075*(abs(err_rx) + abs(err_ry)) < 0.008\n",
    "  valid_ur = tf.math.reduce_all(tf.stack([cond1, cond2, cond3_ur], axis=1), axis=1)\n",
    "  valid_ku = tf.math.reduce_all(tf.stack([cond1, cond2, cond3_ku], axis=1), axis=1)\n",
    "  #ret = tf.stack([valid_ur, cond1, cond2, cond3_ur], axis=1)\n",
    "  ret = tf.stack([valid_ur, valid_ku], axis=1)\n",
    "  ret = tf.cast(ret, tf.int8)\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validity(err):\n",
    "  err_rx, err_ry, err_rz, err_x, err_y, err_z = err.numpy()\n",
    "  cond1 = abs(err_rx) + abs(err_ry) < 0.052\n",
    "  cond2 = abs(err_x) + abs(err_y) < 0.007\n",
    "  cond3_ur = abs(err_z) < 0.04\n",
    "  cond3_ku = abs(err_z) + 0.075*(abs(err_rx) + abs(err_ry)) < 0.008\n",
    "  valid_ur = cond1 and cond2 and cond3_ur\n",
    "  valid_ku = cond1 and cond2 and cond3_ku\n",
    "  #return int(valid_ur), int(valid_ku)\n",
    "  retnp = int(valid_ur), int(valid_ku), int(cond1), int(cond2), int(cond3_ur), int(cond3_ku)\n",
    "  #retnp = int(cond1)\n",
    "  ret = tf.convert_to_tensor(retnp, dtype=tf.float32)\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, faketrain_dataset = create_dataset(res, ximg, yimg)\n",
    "train_dataset = train_dataset.batch(GLOBAL_BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(GLOBAL_BATCH_SIZE)\n",
    "faketrain_dataset = faketrain_dataset.batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "model = create_model(DEPTH)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, beta_1=0.5)\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "test_log_dir = 'logs/' + current_time\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(inputs):\n",
    "  fpath, images, y = inputs\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images, training=True)\n",
    "    loss = compute_loss(y, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  print(f\"===EPOCH {epoch}===\")\n",
    "  # TRAIN LOOP\n",
    "  total_loss = 0.0\n",
    "  nb = 0\n",
    "  #for inputs in faketrain_dataset:\n",
    "  for inputs in train_dataset:\n",
    "    loss = train_step(inputs)\n",
    "    nb = nb + 1\n",
    "    #print(f\"Loss {nb} ... \", loss)\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "\n",
    "  # TEST LOOP\n",
    "  nt = 0\n",
    "  print()\n",
    "  print(f\"===TESTING===\")\n",
    "\n",
    "  b = 0; loss = np.zeros((TEST_DATABASE_LENGTH, 1))\n",
    "  for inputs in test_dataset:\n",
    "    _, images, y = inputs\n",
    "    predictions = model(images)\n",
    "    nb = predictions.shape[0]\n",
    "    GBS = GLOBAL_BATCH_SIZE\n",
    "    loss[b*GBS:b*GBS+nb] = compute_loss(y, predictions).numpy()\n",
    "    b += 1\n",
    "  avg_loss = tf.reduce_mean(loss).numpy()\n",
    "  print(f\"loss of predictions ... , {avg_loss:.8f}\")  \n",
    "  with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', avg_loss, step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Průběh učení pro DEPTH=2 (oranž.), DEPTH=4 (modrá), DEPTH=6 (červená) a DEPTH=8 (sv. modrá)\n",
    "\n",
    "<img src=\"loss.jpg\" alt=\"loss\" style=\"width: 938px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf22",
   "language": "python",
   "name": "tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
